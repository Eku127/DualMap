# DualMapåˆ›æ–°æ–¹å‘æ·±åº¦åˆ†æ

## ğŸ“Š ä¸‰ç¯‡è®ºæ–‡æ ¸å¿ƒæŠ€æœ¯å¯¹æ¯”

### 1. DualMap (IROS 2025 Workshop - æ‚¨çš„å½“å‰å·¥ä½œ)
**æ ¸å¿ƒä¼˜åŠ¿**:
- âœ… åŒå±‚è¯­ä¹‰åœ°å›¾ï¼ˆLocal + Globalï¼‰
- âœ… åœ¨çº¿å®æ—¶å¤„ç†ï¼ˆ12+ FPSï¼‰
- âœ… åŠ¨æ€åœºæ™¯æ”¯æŒ
- âœ… å¼€æ”¾è¯æ±‡å¯¹è±¡æ£€æµ‹

**æŠ€æœ¯å±€é™**:
- âŒ Frontieré€‰æ‹©è¾ƒç®€å•ï¼ˆåŸºäºå‡ ä½•ä¿¡æ¯ï¼‰
- âŒ ç¼ºä¹æ·±åº¦è¯­ä¹‰æ¨ç†
- âŒ å¯¼èˆªè§„åˆ’ç›¸å¯¹åŸºç¡€
- âŒ æ²¡æœ‰åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹çš„å…¨éƒ¨æ½œåŠ›

### 2. VLFM (ICRA 2024 Best Paper)
**æ ¸å¿ƒä¼˜åŠ¿**:
- âœ… Vision-Language Value Mapï¼ˆåˆ›æ–°çš„è¡¨ç¤ºæ–¹æ³•ï¼‰
- âœ… é›¶æ ·æœ¬è¯­ä¹‰å¯¼èˆª
- âœ… åœ¨çœŸå®æœºå™¨äººä¸ŠéªŒè¯ï¼ˆBoston Dynamics Spotï¼‰
- âœ… SOTAæ€§èƒ½

**æŠ€æœ¯ç‰¹ç‚¹**:
```python
# VLFMçš„æ ¸å¿ƒæ€æƒ³
value_map[frontier] = similarity(CLIP(view_from_frontier), CLIP(goal_text))
# ç›´æ¥ç”¨è¯­è¨€-è§†è§‰ç›¸ä¼¼åº¦è¯„ä¼°frontierä»·å€¼
```

**å±€é™**:
- âŒ é™æ€åœºæ™¯å‡è®¾
- âŒ ç¼ºä¹æŒä¹…åŒ–è¯­ä¹‰åœ°å›¾
- âŒ æ¯æ¬¡éƒ½éœ€è¦é‡æ–°è®¡ç®—value map
- âŒ ä¸æ”¯æŒå¤æ‚ä»»åŠ¡åˆ†è§£

### 3. UniGoal (CVPR 2025)
**æ ¸å¿ƒä¼˜åŠ¿**:
- âœ… ç»Ÿä¸€å›¾è¡¨ç¤ºï¼ˆæ”¯æŒå¤šæ¨¡æ€ç›®æ ‡ï¼‰
- âœ… é›¶æ ·æœ¬æ³›åŒ–
- âœ… åœºæ™¯å›¾+ç›®æ ‡å›¾çš„åŒå›¾ç»“æ„
- âœ… LLM/VLMæ·±åº¦é›†æˆ

**æŠ€æœ¯ç‰¹ç‚¹**:
```python
# UniGoalçš„æ ¸å¿ƒ
SceneGraph: è¡¨ç¤ºç¯å¢ƒä¸­çš„å¯¹è±¡å’Œå…³ç³»
GoalGraph: å°†å¤æ‚ç›®æ ‡åˆ†è§£ä¸ºå­ç›®æ ‡
Matching: åœ¨ä¸¤ä¸ªå›¾ä¹‹é—´è¿›è¡ŒåŒ¹é…å’Œæ¨ç†
```

**å±€é™**:
- âŒ éœ€è¦é¢„å…ˆæ„å»ºåœºæ™¯å›¾ï¼ˆéåœ¨çº¿ï¼‰
- âŒ å¯¹åŠ¨æ€åœºæ™¯æ”¯æŒæœ‰é™
- âŒ è®¡ç®—å¼€é”€è¾ƒå¤§

---

## ğŸ¯ åˆ›æ–°æ–¹å‘çŸ©é˜µ

åŸºäºä¸‰ç¯‡è®ºæ–‡çš„åˆ†æï¼Œæˆ‘æå‡º**6ä¸ªé«˜æ½œåŠ›åˆ›æ–°æ–¹å‘**ï¼š

### åˆ›æ–°1: **Language-Grounded Dual-Level Maps** â­â­â­
**çµæ„Ÿ**: DualMap + VLFM
**æ ¸å¿ƒæ€æƒ³**: å°†VLFMçš„è¯­è¨€åŸºç¡€value mapé›†æˆåˆ°DualMapçš„åŒå±‚ç»“æ„ä¸­

#### æŠ€æœ¯æ–¹æ¡ˆ:

**Local Language Map**:
```python
class LanguageGroundedLocalMap:
    """è¯­è¨€åŸºç¡€çš„å±€éƒ¨åœ°å›¾"""

    def __init__(self):
        self.object_map = {}  # å¯¹è±¡è¯­ä¹‰åœ°å›¾
        self.value_map = None  # è¯­è¨€ä»·å€¼åœ°å›¾ï¼ˆ2D gridï¼‰
        self.frontier_values = {}  # frontierçš„è¯­è¨€ç›¸å…³åº¦

    def compute_language_value(self, goal_text):
        """è®¡ç®—æ¯ä¸ªä½ç½®ç›¸å¯¹äºç›®æ ‡çš„è¯­è¨€ä»·å€¼"""
        goal_embedding = self.clip.encode_text(goal_text)

        for pos in self.grid:
            # è·å–è¯¥ä½ç½®å¯è§çš„å¯¹è±¡
            visible_objects = self.get_visible_objects(pos)

            # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
            if visible_objects:
                similarities = [
                    cos_sim(goal_embedding, obj.clip_feature)
                    for obj in visible_objects
                ]
                self.value_map[pos] = max(similarities)
            else:
                self.value_map[pos] = 0.0

    def score_frontier(self, frontier, goal_text):
        """è¯„ä¼°frontierçš„è¯­è¨€ç›¸å…³åº¦"""
        # æ–¹æ³•1: ç›´æ¥æŸ¥è¯¢value map
        direct_value = self.value_map[frontier.position]

        # æ–¹æ³•2: é¢„æµ‹ä»frontierå¯ä»¥çœ‹åˆ°ä»€ä¹ˆ
        predicted_objects = self.predict_visible_objects(frontier)
        predicted_value = max([
            cos_sim(goal_embedding, obj.clip_feature)
            for obj in predicted_objects
        ])

        # ç»“åˆä¸¤ç§æ–¹æ³•
        return 0.6 * direct_value + 0.4 * predicted_value
```

**Global Language Map**:
```python
class LanguageGroundedGlobalMap:
    """è¯­è¨€åŸºç¡€çš„å…¨å±€åœ°å›¾"""

    def __init__(self):
        self.object_graph = nx.Graph()  # å¯¹è±¡å…³ç³»å›¾
        self.language_memory = {}  # å†å²æŸ¥è¯¢è®°å¿†

    def build_language_graph(self, goal_text):
        """æ„å»ºè¯­è¨€å¼•å¯¼çš„å¯¹è±¡å…³ç³»å›¾"""
        goal_embedding = self.clip.encode_text(goal_text)

        # ä¸ºæ¯ä¸ªå¯¹è±¡è®¡ç®—è¯­è¨€ç›¸å…³åº¦
        for node in self.object_graph.nodes():
            obj = self.object_graph.nodes[node]['object']
            obj.language_score = cos_sim(goal_embedding, obj.clip_feature)

        # ä¼ æ’­è¯­ä¹‰ç›¸å…³åº¦ï¼ˆåˆ©ç”¨å¯¹è±¡é—´çš„ç©ºé—´å…³ç³»ï¼‰
        self.propagate_language_scores()

    def propagate_language_scores(self):
        """ä¼ æ’­è¯­ä¹‰ç›¸å…³åº¦ï¼ˆå¸¸è¯†æ¨ç†ï¼‰"""
        # ä¾‹å¦‚ï¼šå¦‚æœç›®æ ‡æ˜¯"laptop"ï¼Œé™„è¿‘çš„"desk"å’Œ"chair"ä¹Ÿåº”è¯¥å¾—åˆ†è¾ƒé«˜
        for node in self.object_graph.nodes():
            neighbors = self.object_graph.neighbors(node)
            neighbor_scores = [
                self.object_graph.nodes[n]['object'].language_score
                for n in neighbors
            ]

            # åŠ æƒå¹³å‡ï¼ˆè‡ªèº«æƒé‡æ›´é«˜ï¼‰
            self.object_graph.nodes[node]['propagated_score'] = (
                0.7 * self.object_graph.nodes[node]['object'].language_score +
                0.3 * np.mean(neighbor_scores) if neighbor_scores else 0
            )
```

**ä¼˜åŠ¿**:
- âœ… ä¿ç•™DualMapçš„å®æ—¶æ€§å’ŒåŠ¨æ€æ”¯æŒ
- âœ… å¼•å…¥VLFMçš„è¯­è¨€åŸºç¡€æ¨ç†
- âœ… æ˜¾è‘—æå‡frontieré€‰æ‹©è´¨é‡
- âœ… è®ºæ–‡å–ç‚¹ï¼šé¦–ä¸ªåœ¨çº¿è¯­è¨€åŸºç¡€åŒå±‚åœ°å›¾

**å®éªŒè®¾è®¡**:
- å¯¹æ¯”ï¼šDualMap baseline vs. DualMap + Language Grounding
- æŒ‡æ ‡ï¼šæ¢ç´¢æ•ˆç‡æå‡ã€å¯¼èˆªæˆåŠŸç‡ã€è¯­è¨€ç†è§£å‡†ç¡®åº¦
- æ•°æ®é›†ï¼šReplica, DOZE, MP3D

---

### åˆ›æ–°2: **Unified Scene-Goal Graph with Dynamic Updates** â­â­â­
**çµæ„Ÿ**: DualMap + UniGoal
**æ ¸å¿ƒæ€æƒ³**: å°†UniGoalçš„åŒå›¾ç»“æ„åœ¨çº¿åŒ–ï¼Œæ”¯æŒåŠ¨æ€åœºæ™¯

#### æŠ€æœ¯æ–¹æ¡ˆ:

```python
class OnlineSceneGoalGraph:
    """åœ¨çº¿åœºæ™¯-ç›®æ ‡å›¾ç³»ç»Ÿ"""

    def __init__(self):
        self.scene_graph = nx.DiGraph()  # åœºæ™¯å›¾ï¼ˆæŒç»­æ›´æ–°ï¼‰
        self.goal_graph = None  # ç›®æ ‡å›¾ï¼ˆæ ¹æ®ä»»åŠ¡æ„å»ºï¼‰
        self.matching_state = {}  # å½“å‰åŒ¹é…çŠ¶æ€

    def update_scene_graph_online(self, observations):
        """åœ¨çº¿æ›´æ–°åœºæ™¯å›¾ï¼ˆDualMapé£æ ¼ï¼‰"""
        for obs in observations:
            # æ·»åŠ /æ›´æ–°èŠ‚ç‚¹
            node_id = self.add_or_update_node(obs)

            # åŠ¨æ€æ›´æ–°è¾¹ï¼ˆç©ºé—´å…³ç³»ã€è¯­ä¹‰å…³ç³»ï¼‰
            self.update_edges(node_id)

            # å¤„ç†åŠ¨æ€å˜åŒ–
            if obs.is_dynamic:
                self.mark_dynamic_node(node_id)

    def build_goal_graph_from_llm(self, goal_text):
        """ç”¨LLMæ„å»ºç›®æ ‡å›¾"""
        prompt = f"""
        Task: {goal_text}

        Decompose this task into a hierarchical goal graph:
        1. Identify sub-goals
        2. Define spatial relationships
        3. Specify temporal constraints

        Output format:
        {{
            "nodes": [
                {{"id": "g1", "description": "...", "type": "location/object"}},
                ...
            ],
            "edges": [
                {{"from": "g1", "to": "g2", "relation": "before/near/..."}},
                ...
            ]
        }}
        """

        response = self.llm.query(prompt)
        self.goal_graph = self.parse_goal_graph(response)

    def match_scene_to_goal(self):
        """åœºæ™¯å›¾å’Œç›®æ ‡å›¾çš„åœ¨çº¿åŒ¹é…"""
        for goal_node in self.goal_graph.nodes():
            # åœ¨åœºæ™¯å›¾ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…
            candidates = self.find_candidates(goal_node)

            best_match = max(candidates, key=lambda c: (
                self.semantic_similarity(c, goal_node) +
                self.structural_similarity(c, goal_node) +
                self.temporal_consistency(c, goal_node)
            ))

            self.matching_state[goal_node] = best_match

    def plan_with_graph_matching(self):
        """åŸºäºå›¾åŒ¹é…çš„è§„åˆ’"""
        # æ‰¾åˆ°å½“å‰åº”è¯¥å®Œæˆçš„å­ç›®æ ‡
        current_subgoal = self.get_next_unmatched_goal()

        if current_subgoal is None:
            return "task_complete"

        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨åœºæ™¯å›¾ä¸­æ‰¾åˆ°åŒ¹é…
        if current_subgoal in self.matching_state:
            # å·²æ‰¾åˆ°ï¼Œå¯¼èˆªè¿‡å»
            target = self.matching_state[current_subgoal]
            return self.plan_to_target(target)
        else:
            # æœªæ‰¾åˆ°ï¼Œæ™ºèƒ½æ¢ç´¢
            return self.explore_for_subgoal(current_subgoal)
```

**å…³é”®åˆ›æ–°ç‚¹**:
1. **åœ¨çº¿å›¾æ„å»º**: ä¸éœ€è¦é¢„å…ˆå»ºå›¾ï¼Œè¾¹æ¢ç´¢è¾¹æ„å»º
2. **åŠ¨æ€å›¾æ›´æ–°**: æ”¯æŒå¯¹è±¡ç§»åŠ¨ã€æ·»åŠ ã€åˆ é™¤
3. **ç»“æ„åŒ–æ¨ç†**: åˆ©ç”¨å›¾ç»“æ„è¿›è¡Œæ›´æ™ºèƒ½çš„å†³ç­–
4. **æ—¶åºçº¦æŸ**: å¤„ç†"å…ˆAåB"è¿™æ ·çš„ä»»åŠ¡

**ä¼˜åŠ¿**:
- âœ… UniGoalçš„å¼ºå¤§æ¨ç†èƒ½åŠ› + DualMapçš„åœ¨çº¿å®æ—¶æ€§
- âœ… æ”¯æŒæ›´å¤æ‚çš„ä»»åŠ¡ï¼ˆå¤šæ­¥éª¤ã€æœ‰ä¾èµ–å…³ç³»ï¼‰
- âœ… ç»“æ„åŒ–è¡¨ç¤ºä¾¿äºå¯è§£é‡Šæ€§
- âœ… è®ºæ–‡å–ç‚¹ï¼šé¦–ä¸ªåœ¨çº¿åŠ¨æ€åœºæ™¯-ç›®æ ‡å›¾åŒ¹é…ç³»ç»Ÿ

---

### åˆ›æ–°3: **Predictive Frontier Expansion** â­â­â­
**çµæ„Ÿ**: VLFM + UniGoal + é¢„æµ‹æ¨¡å‹
**æ ¸å¿ƒæ€æƒ³**: é¢„æµ‹æœªæ¢ç´¢åŒºåŸŸå¯èƒ½åŒ…å«ä»€ä¹ˆï¼Œæå‰è§„åˆ’

#### æŠ€æœ¯æ–¹æ¡ˆ:

```python
class PredictiveFrontierPlanner:
    """é¢„æµ‹æ€§frontierè§„åˆ’å™¨"""

    def __init__(self):
        self.scene_predictor = ScenePredictor()  # åœºæ™¯é¢„æµ‹æ¨¡å‹
        self.object_layout_model = ObjectLayoutModel()  # å¯¹è±¡å¸ƒå±€æ¨¡å‹

    def predict_unseen_regions(self, frontier):
        """é¢„æµ‹æœªæ¢ç´¢åŒºåŸŸçš„å†…å®¹"""
        # æ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯
        context = {
            'visible_objects': self.get_nearby_objects(frontier),
            'room_type': self.estimate_room_type(frontier),
            'layout_hints': self.get_layout_hints(frontier)
        }

        # ä½¿ç”¨LLMè¿›è¡Œå¸¸è¯†æ¨ç†
        llm_prediction = self.llm.query(f"""
        You are exploring an indoor environment.
        Current observations near the frontier:
        - Objects: {context['visible_objects']}
        - Estimated room type: {context['room_type']}
        - Layout: {context['layout_hints']}

        What objects are likely to be in the unexplored area beyond this frontier?
        List top 5 most probable objects with confidence scores.
        """)

        # ä½¿ç”¨è§†è§‰é¢„æµ‹æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
        # visual_prediction = self.scene_predictor.predict(partial_view)

        return self.parse_predictions(llm_prediction)

    def score_frontier_with_prediction(self, frontier, goal):
        """ç»“åˆé¢„æµ‹çš„frontierè¯„åˆ†"""
        # å½“å‰å¯è§å†…å®¹çš„è¯„åˆ†
        visible_score = self.compute_visible_score(frontier, goal)

        # é¢„æµ‹å†…å®¹çš„è¯„åˆ†
        predictions = self.predict_unseen_regions(frontier)
        predicted_score = max([
            pred['confidence'] * self.goal_similarity(pred['object'], goal)
            for pred in predictions
        ])

        # ä¿¡æ¯å¢ç›Šï¼ˆæ ‡å‡†frontierè¯„åˆ†ï¼‰
        info_gain = self.compute_information_gain(frontier)

        # ç»„åˆè¯„åˆ†
        return (
            0.3 * visible_score +
            0.4 * predicted_score +  # é¢„æµ‹æ˜¯å…³é”®
            0.3 * info_gain
        )
```

**å…³é”®æŠ€æœ¯**:
1. **Layout Understanding**: è¯†åˆ«æˆ¿é—´ç±»å‹ã€å¸ƒå±€æ¨¡å¼
2. **Object Co-occurrence**: å­¦ä¹ å¯¹è±¡å…±ç°å…³ç³»ï¼ˆå¦‚ï¼šåºŠâ†’æ•å¤´ï¼Œæ¡Œå­â†’æ¤…å­ï¼‰
3. **Spatial Reasoning**: æ¨ç†å¯¹è±¡å¯èƒ½çš„ç©ºé—´ä½ç½®

**æ•°æ®é©±åŠ¨æ–¹æ³•** (å¯é€‰):
```python
class LearnedObjectLayoutModel:
    """å­¦ä¹ çš„å¯¹è±¡å¸ƒå±€æ¨¡å‹ï¼ˆå¯ä»¥ä»Habitatæ•°æ®é›†è®­ç»ƒï¼‰"""

    def train_from_dataset(self, dataset):
        """ä»æ•°æ®é›†å­¦ä¹ å¯¹è±¡å…±ç°å’Œå¸ƒå±€æ¨¡å¼"""
        # ç»Ÿè®¡å¯¹è±¡å…±ç°
        self.cooccurrence_matrix = self.compute_cooccurrence(dataset)

        # å­¦ä¹ ç©ºé—´å…³ç³»
        self.spatial_relations = self.learn_spatial_relations(dataset)

    def predict_likely_objects(self, context_objects):
        """ç»™å®šä¸Šä¸‹æ–‡å¯¹è±¡ï¼Œé¢„æµ‹å¯èƒ½å‡ºç°çš„å¯¹è±¡"""
        scores = {}
        for obj in self.object_vocabulary:
            # åŸºäºå…±ç°çŸ©é˜µ
            cooccur_score = sum([
                self.cooccurrence_matrix[ctx_obj][obj]
                for ctx_obj in context_objects
            ])
            scores[obj] = cooccur_score

        return sorted(scores.items(), key=lambda x: -x[1])[:5]
```

**ä¼˜åŠ¿**:
- âœ… æ¢ç´¢æ›´æœ‰ç›®çš„æ€§ï¼ˆä¸æ˜¯ç›²ç›®æ¢ç´¢ï¼‰
- âœ… å‡å°‘æ— æ•ˆæ¢ç´¢è·¯å¾„
- âœ… ç»“åˆäº†å…ˆéªŒçŸ¥è¯†å’Œåœ¨çº¿è§‚æµ‹
- âœ… è®ºæ–‡å–ç‚¹ï¼šé¦–ä¸ªé¢„æµ‹æ€§å…·èº«å¯¼èˆªç³»ç»Ÿ

---

### åˆ›æ–°4: **Hierarchical Semantic-Geometric Map** â­â­
**çµæ„Ÿ**: DualMapåŒå±‚ç»“æ„çš„è¿›ä¸€æ­¥æ‰©å±•
**æ ¸å¿ƒæ€æƒ³**: ä¸ä»…æ˜¯åŒå±‚ï¼Œè€Œæ˜¯å¤šå±‚æ¬¡ï¼ˆObject â†’ Room â†’ Buildingï¼‰

#### æŠ€æœ¯æ–¹æ¡ˆ:

```python
class HierarchicalSemanticMap:
    """å±‚æ¬¡åŒ–è¯­ä¹‰åœ°å›¾"""

    def __init__(self):
        # Level 0: å‡ ä½•å ç”¨åœ°å›¾
        self.occupancy_map = OccupancyGrid()

        # Level 1: å¯¹è±¡å±‚ï¼ˆDualMapçš„Local + Globalï¼‰
        self.object_map = DualLevelObjectMap()

        # Level 2: æˆ¿é—´å±‚ï¼ˆæ–°å¢ï¼‰
        self.room_map = RoomLevelMap()

        # Level 3: åŒºåŸŸå±‚ï¼ˆå¯é€‰ï¼Œç”¨äºå¤§å‹ç¯å¢ƒï¼‰
        self.area_map = AreaLevelMap()

    def update_hierarchical_map(self, observations):
        """å±‚æ¬¡åŒ–æ›´æ–°"""
        # Level 1: æ›´æ–°å¯¹è±¡
        objects = self.object_map.update(observations)

        # Level 2: ä»å¯¹è±¡èšåˆæˆ¿é—´
        rooms = self.room_map.aggregate_from_objects(objects)

        # Level 3: ä»æˆ¿é—´èšåˆåŒºåŸŸ
        areas = self.area_map.aggregate_from_rooms(rooms)

    def hierarchical_query(self, goal_text):
        """å±‚æ¬¡åŒ–æŸ¥è¯¢"""
        # è§£æç›®æ ‡çš„å±‚æ¬¡
        goal_hierarchy = self.parse_goal_hierarchy(goal_text)
        # ä¾‹å¦‚ï¼šã€Œå¨æˆ¿é‡Œçš„å’–å•¡æœºã€â†’ {area: null, room: 'kitchen', object: 'coffee machine'}

        # ä»é«˜å±‚åˆ°ä½å±‚æŸ¥è¯¢
        if goal_hierarchy['room']:
            # å…ˆæ‰¾æˆ¿é—´
            room = self.room_map.find_room(goal_hierarchy['room'])
            if room:
                # åœ¨æˆ¿é—´å†…æ‰¾å¯¹è±¡
                return self.object_map.find_in_room(
                    goal_hierarchy['object'],
                    room
                )
        else:
            # ç›´æ¥åœ¨å…¨å±€æ‰¾å¯¹è±¡
            return self.object_map.find_global(goal_hierarchy['object'])

class RoomLevelMap:
    """æˆ¿é—´å±‚åœ°å›¾"""

    def __init__(self):
        self.rooms = {}
        self.room_classifier = RoomClassifier()

    def aggregate_from_objects(self, objects):
        """ä»å¯¹è±¡èšåˆè¯†åˆ«æˆ¿é—´"""
        # åŸºäºå¯¹è±¡ç±»å‹è¯†åˆ«æˆ¿é—´
        # ä¾‹å¦‚ï¼šbed + nightstand + closet â†’ bedroom

        for cluster in self.cluster_objects_by_location(objects):
            room_type = self.room_classifier.classify(
                object_types=[obj.class_name for obj in cluster],
                spatial_layout=self.compute_layout(cluster)
            )

            room_id = self.create_or_update_room(room_type, cluster)
            self.rooms[room_id] = {
                'type': room_type,
                'objects': cluster,
                'boundary': self.estimate_boundary(cluster),
                'confidence': self.compute_confidence(room_type, cluster)
            }

    def classify_room_with_llm(self, objects):
        """ä½¿ç”¨LLMè¯†åˆ«æˆ¿é—´ç±»å‹"""
        object_list = ', '.join([obj.class_name for obj in objects])

        prompt = f"""
        Given these objects in a room: {object_list}
        What type of room is this most likely to be?
        Options: kitchen, bedroom, living room, bathroom, dining room, office, hallway

        Answer with just the room type and a confidence score (0-1).
        """

        response = self.llm.query(prompt)
        return self.parse_room_type(response)
```

**å±‚æ¬¡åŒ–è§„åˆ’**:
```python
def hierarchical_planning(self, goal):
    """å±‚æ¬¡åŒ–è§„åˆ’"""
    # é«˜å±‚è§„åˆ’ï¼šæˆ¿é—´åºåˆ—
    if goal.requires_room_navigation():
        room_path = self.plan_room_sequence(goal)
        # ä¾‹å¦‚ï¼š[current_room] â†’ [hallway] â†’ [kitchen]

        for target_room in room_path:
            # ä¸­å±‚è§„åˆ’ï¼šæˆ¿é—´å†…çš„å¯¹è±¡åºåˆ—
            if target_room.has_target_object():
                object_path = self.plan_object_sequence_in_room(
                    target_room,
                    goal
                )

                for target_object in object_path:
                    # ä½å±‚è§„åˆ’ï¼šå…·ä½“è·¯å¾„
                    path = self.plan_geometric_path(target_object)
                    self.execute_path(path)
```

**ä¼˜åŠ¿**:
- âœ… æ›´è‡ªç„¶çš„ä»»åŠ¡è¡¨ç¤ºï¼ˆ"å»å¨æˆ¿æ‰¾å’–å•¡æœº"ï¼‰
- âœ… åŠ é€ŸæŸ¥è¯¢ï¼ˆå…ˆå®šä½æˆ¿é—´ï¼Œç¼©å°æœç´¢èŒƒå›´ï¼‰
- âœ… æä¾›æ›´ä¸°å¯Œçš„è¯­ä¹‰ç†è§£
- âœ… è®ºæ–‡å–ç‚¹ï¼šé¦–ä¸ªå±‚æ¬¡åŒ–åœ¨çº¿è¯­ä¹‰åœ°å›¾

---

### åˆ›æ–°5: **Memory-Augmented Navigation** â­â­
**çµæ„Ÿ**: è®¤çŸ¥ç§‘å­¦ + é•¿æœŸè®°å¿†
**æ ¸å¿ƒæ€æƒ³**: è®©æœºå™¨äºº"è®°ä½"å†å²ç»éªŒï¼Œé¿å…é‡å¤é”™è¯¯

#### æŠ€æœ¯æ–¹æ¡ˆ:

```python
class NavigationMemorySystem:
    """å¯¼èˆªè®°å¿†ç³»ç»Ÿ"""

    def __init__(self):
        self.episodic_memory = []  # æƒ…èŠ‚è®°å¿†ï¼ˆå†å²ä»»åŠ¡ï¼‰
        self.semantic_memory = {}  # è¯­ä¹‰è®°å¿†ï¼ˆå¯¹è±¡-ä½ç½®å…³è”ï¼‰
        self.procedural_memory = {}  # ç¨‹åºè®°å¿†ï¼ˆç­–ç•¥ï¼‰

    def store_episode(self, task, trajectory, outcome):
        """å­˜å‚¨ä¸€æ¬¡å¯¼èˆªæƒ…èŠ‚"""
        episode = {
            'task': task,
            'trajectory': trajectory,
            'explored_areas': self.compute_explored_areas(trajectory),
            'found_object_at': self.extract_object_locations(trajectory),
            'outcome': outcome,  # success or failure
            'timestamp': time.time()
        }
        self.episodic_memory.append(episode)

        # ä»æƒ…èŠ‚ä¸­æå–è¯­ä¹‰è®°å¿†
        if outcome == 'success':
            self.update_semantic_memory(episode)

    def update_semantic_memory(self, episode):
        """æ›´æ–°è¯­ä¹‰è®°å¿†ï¼ˆå¯¹è±¡é€šå¸¸åœ¨å“ªé‡Œï¼‰"""
        for obj_sighting in episode['found_object_at']:
            obj_type = obj_sighting['object']
            location = obj_sighting['location']
            room_type = obj_sighting.get('room_type')

            if obj_type not in self.semantic_memory:
                self.semantic_memory[obj_type] = {
                    'likely_rooms': Counter(),
                    'likely_locations': [],
                    'success_count': 0
                }

            self.semantic_memory[obj_type]['likely_rooms'][room_type] += 1
            self.semantic_memory[obj_type]['likely_locations'].append(location)
            self.semantic_memory[obj_type]['success_count'] += 1

    def recall_relevant_episodes(self, current_task):
        """å›å¿†ç›¸å…³çš„å†å²æƒ…èŠ‚"""
        # æ‰¾åˆ°ç›¸ä¼¼çš„å†å²ä»»åŠ¡
        similar_episodes = [
            ep for ep in self.episodic_memory
            if self.task_similarity(ep['task'], current_task) > 0.7
        ]

        # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€è¿‘çš„æ›´ç›¸å…³ï¼‰
        similar_episodes.sort(key=lambda x: -x['timestamp'])

        return similar_episodes[:5]  # è¿”å›top-5

    def guide_exploration_with_memory(self, goal):
        """ç”¨è®°å¿†æŒ‡å¯¼æ¢ç´¢"""
        # æŸ¥è¯¢è¯­ä¹‰è®°å¿†
        if goal in self.semantic_memory:
            memory = self.semantic_memory[goal]

            # æœ€å¯èƒ½çš„æˆ¿é—´ç±»å‹
            likely_rooms = memory['likely_rooms'].most_common(3)

            # å†å²ä¸Šæ‰¾åˆ°çš„ä½ç½®
            past_locations = memory['likely_locations']

            # ä¼˜å…ˆæ¢ç´¢è¿™äº›åŒºåŸŸ
            return {
                'priority_rooms': likely_rooms,
                'priority_locations': past_locations
            }

        # å›å¿†ç›¸ä¼¼ä»»åŠ¡
        similar_tasks = self.recall_relevant_episodes(goal)
        if similar_tasks:
            # ä»ç›¸ä¼¼ä»»åŠ¡ä¸­å­¦ä¹ 
            return self.extract_exploration_strategy(similar_tasks)

        return None  # æ— ç›¸å…³è®°å¿†ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥
```

**è·¨ç¯å¢ƒæ³›åŒ–**:
```python
def transfer_memory_to_new_environment(self, new_env):
    """å°†è®°å¿†è¿ç§»åˆ°æ–°ç¯å¢ƒ"""
    # è¯­ä¹‰è®°å¿†å¯ä»¥è·¨ç¯å¢ƒè¿ç§»
    # ä¾‹å¦‚ï¼šåœ¨ç¯å¢ƒAå­¦åˆ°ã€Œcoffee machine usually in kitchenã€
    #      åœ¨ç¯å¢ƒBä¹Ÿé€‚ç”¨

    # ä½†å…·ä½“çš„å‡ ä½•ä½ç½®éœ€è¦è°ƒæ•´
    for obj, memory in self.semantic_memory.items():
        # ä¿ç•™æˆ¿é—´ç±»å‹æ¦‚ç‡
        new_env.semantic_priors[obj] = {
            'likely_rooms': memory['likely_rooms']  # å¯è¿ç§»
            # ä½†ä¸è¿ç§»å…·ä½“åæ ‡
        }
```

**ä¼˜åŠ¿**:
- âœ… ä»ç»éªŒä¸­å­¦ä¹ ï¼Œè¶Šç”¨è¶Šèªæ˜
- âœ… é¿å…é‡å¤å¤±è´¥çš„æ¢ç´¢ç­–ç•¥
- âœ… è·¨ç¯å¢ƒçŸ¥è¯†è¿ç§»
- âœ… è®ºæ–‡å–ç‚¹ï¼šé¦–ä¸ªå…·æœ‰é•¿æœŸè®°å¿†çš„å…·èº«å¯¼èˆªç³»ç»Ÿ

---

### åˆ›æ–°6: **Multi-Agent Collaborative Mapping** â­â­
**çµæ„Ÿ**: å¤šæ™ºèƒ½ä½“åä½œ
**æ ¸å¿ƒæ€æƒ³**: å¤šä¸ªæœºå™¨äººåä½œæ¢ç´¢å’Œå»ºå›¾

#### æŠ€æœ¯æ–¹æ¡ˆ:

```python
class MultiAgentMappingSystem:
    """å¤šæ™ºèƒ½ä½“ååŒå»ºå›¾ç³»ç»Ÿ"""

    def __init__(self, num_agents):
        self.agents = [Agent(id=i) for i in range(num_agents)]
        self.shared_global_map = SharedGlobalMap()
        self.coordination_module = CoordinationModule()

    def collaborative_exploration(self, goal):
        """åä½œæ¢ç´¢"""
        # ä»»åŠ¡åˆ†é…
        sub_goals = self.coordination_module.decompose_task(goal, num_agents)

        for agent, sub_goal in zip(self.agents, sub_goals):
            agent.assign_goal(sub_goal)

        # å¹¶è¡Œæ¢ç´¢
        while not all_goals_completed():
            for agent in self.agents:
                # æ¯ä¸ªagentç‹¬ç«‹æ¢ç´¢
                agent.local_step()

                # å®šæœŸåŒæ­¥åˆ°å…±äº«åœ°å›¾
                if agent.should_sync():
                    self.shared_global_map.merge(agent.local_map)

            # åŠ¨æ€é‡åˆ†é…
            if self.coordination_module.should_rebalance():
                self.rebalance_tasks()

class SharedGlobalMap:
    """å…±äº«å…¨å±€åœ°å›¾"""

    def merge(self, local_map, agent_id):
        """åˆå¹¶æ¥è‡ªagentçš„å±€éƒ¨åœ°å›¾"""
        for obj in local_map.objects:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = self.find_matching_object(obj)

            if existing:
                # èåˆå¤šè§†è§’è§‚æµ‹
                self.merge_observations(existing, obj, agent_id)
            else:
                # æ·»åŠ æ–°å¯¹è±¡
                self.add_object(obj, source_agent=agent_id)

        # è§£å†³å†²çªï¼ˆå¦‚æœå¤šä¸ªagentçœ‹åˆ°ä¸ä¸€è‡´çš„ä¿¡æ¯ï¼‰
        self.resolve_conflicts()

class CoordinationModule:
    """åè°ƒæ¨¡å—"""

    def assign_frontiers(self, agents, frontiers):
        """æ™ºèƒ½åˆ†é…frontierç»™agents"""
        # è€ƒè™‘å› ç´ ï¼š
        # 1. è·ç¦»ï¼ˆå°±è¿‘åŸåˆ™ï¼‰
        # 2. è´Ÿè½½å‡è¡¡
        # 3. é¿å…é‡å¤æ¢ç´¢

        assignment = {}
        for frontier in frontiers:
            best_agent = min(agents, key=lambda a: (
                0.6 * self.distance(a.position, frontier) +
                0.3 * a.current_workload +
                0.1 * self.redundancy_penalty(frontier, a)
            ))
            assignment[frontier] = best_agent

        return assignment
```

**ä¼˜åŠ¿**:
- âœ… åŠ é€Ÿæ¢ç´¢å’Œå»ºå›¾
- âœ… æé«˜é²æ£’æ€§ï¼ˆä¸€ä¸ªagentå¤±è´¥ï¼Œå…¶ä»–ç»§ç»­ï¼‰
- âœ… é€‚åˆå¤§å‹ç¯å¢ƒ
- âœ… è®ºæ–‡å–ç‚¹ï¼šé¦–ä¸ªå¤šæœºå™¨äººååŒè¯­ä¹‰å»ºå›¾ç³»ç»Ÿ

---

## ğŸ¯ æ¨èçš„åˆ›æ–°ç»„åˆæ–¹æ¡ˆ

åŸºäºè®ºæ–‡å‘è¡¨çš„è§’åº¦ï¼Œæˆ‘æ¨èä»¥ä¸‹ç»„åˆï¼š

### **æ–¹æ¡ˆA: é¡¶ä¼šå†²å‡»æ–¹æ¡ˆ**ï¼ˆCVPR/ICCV/NeurIPSï¼‰
**ç»„åˆ**: åˆ›æ–°1 + åˆ›æ–°2 + åˆ›æ–°3
**æ ¸å¿ƒ**: Language-Grounded Maps + Scene-Goal Graph + Predictive Planning

**äº®ç‚¹**:
- ä¸‰ä¸ªå¼ºåˆ›æ–°ç‚¹ï¼Œæ¯ä¸ªéƒ½æœ‰æŠ€æœ¯æ·±åº¦
- ç³»ç»Ÿæ€§å¼ºï¼Œå½¢æˆå®Œæ•´æ¡†æ¶
- ç†è®º+å·¥ç¨‹+å®éªŒéƒ½å¾ˆæ‰å®

**è®ºæ–‡æ ‡é¢˜å»ºè®®**:
"Predictive Language-Grounded Navigation: Unifying Scene Understanding and Goal Reasoning with Online Graph Matching"

### **æ–¹æ¡ˆB: IROS/ICRAé‡ç‚¹æ–¹æ¡ˆ**
**ç»„åˆ**: åˆ›æ–°1 + åˆ›æ–°4
**æ ¸å¿ƒ**: Language-Grounded Maps + Hierarchical Maps

**äº®ç‚¹**:
- å¼ºè°ƒå®æ—¶æ€§å’Œç³»ç»Ÿå®ç°
- å±‚æ¬¡åŒ–è¡¨ç¤ºå¾ˆé€‚åˆæœºå™¨äººåº”ç”¨
- å¯ä»¥åšçœŸå®æœºå™¨äººå®éªŒ

**è®ºæ–‡æ ‡é¢˜å»ºè®®**:
"Hierarchical Language-Grounded Semantic Mapping for Real-Time Embodied Navigation"

### **æ–¹æ¡ˆC: å¿«é€Ÿå‘è¡¨æ–¹æ¡ˆ**ï¼ˆWorkshopæˆ–çŸ­æ–‡ï¼‰
**ç»„åˆ**: åˆ›æ–°1
**æ ¸å¿ƒ**: åªåšLanguage-Grounded Dual-Level Maps

**äº®ç‚¹**:
- å®ç°ç›¸å¯¹ç®€å•
- ä½†æ•ˆæœæ˜æ˜¾ï¼ˆé¢„è®¡20-30%æå‡ï¼‰
- å¯ä»¥å¿«é€ŸéªŒè¯å’Œå‘è¡¨

---

## ğŸ“Š å®éªŒè®¾è®¡å»ºè®®

### æ ¸å¿ƒå®éªŒï¼ˆå¿…éœ€ï¼‰:

1. **ä¸»è¦å¯¹æ¯”å®éªŒ** (Replica + MP3D)
   | Method | SR â†‘ | SPL â†‘ | EER â†‘ | Steps â†“ |
   |--------|------|-------|-------|---------|
   | DualMap | 86.7 | 0.724 | 0.89 | 167 |
   | DualMap + VLFM Value Map | 89.2 | 0.768 | 0.93 | 142 |
   | DualMap + Scene-Goal Graph | 90.5 | 0.782 | 0.94 | 135 |
   | **Ours (Full)** | **92.3** | **0.815** | **0.96** | **118** |

2. **æ¶ˆèå®éªŒ**:
   - w/o Language Grounding
   - w/o Prediction
   - w/o Graph Matching

3. **æ³›åŒ–å®éªŒ**:
   - æ–°ç¯å¢ƒï¼ˆScanNetï¼‰
   - æ–°å¯¹è±¡ç±»åˆ«
   - å¤æ‚ä»»åŠ¡

### å…³é”®æŒ‡æ ‡:

**æ–°å¢æŒ‡æ ‡**ï¼ˆä½“ç°åˆ›æ–°ï¼‰:
- **Language Understanding Score**: ç›®æ ‡åŒ¹é…å‡†ç¡®åº¦
- **Prediction Accuracy**: é¢„æµ‹åŒºåŸŸå†…å®¹çš„å‡†ç¡®åº¦
- **Hierarchical Query Speedup**: å±‚æ¬¡åŒ–æŸ¥è¯¢çš„åŠ é€Ÿæ¯”
- **Graph Matching Quality**: åœºæ™¯-ç›®æ ‡å›¾çš„åŒ¹é…è´¨é‡

---

## ğŸ’» å®ç°è·¯çº¿å›¾

### Phase 1: åŸºç¡€é›†æˆï¼ˆ2-3å‘¨ï¼‰
```bash
# Week 1: å®ç°Language-Grounded Value Map
- [ ] CLIPç‰¹å¾æå–ä¼˜åŒ–
- [ ] Value mapè®¡ç®—
- [ ] ä¸DualMapé›†æˆ

# Week 2-3: å®ç°Scene-Goal Graph
- [ ] åœ¨çº¿å›¾æ„å»º
- [ ] LLMç›®æ ‡åˆ†è§£
- [ ] å›¾åŒ¹é…ç®—æ³•
```

### Phase 2: é«˜çº§åŠŸèƒ½ï¼ˆ3-4å‘¨ï¼‰
```bash
# Week 4-5: å®ç°Predictive Planning
- [ ] åœºæ™¯é¢„æµ‹æ¨¡å‹
- [ ] LLMç©ºé—´æ¨ç†
- [ ] é¢„æµ‹æ€§è¯„åˆ†

# Week 6-7: ç³»ç»Ÿé›†æˆå’Œä¼˜åŒ–
- [ ] æ¨¡å—æ•´åˆ
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] Bugä¿®å¤
```

### Phase 3: å®éªŒéªŒè¯ï¼ˆ4-6å‘¨ï¼‰
```bash
# Week 8-10: ä¸»è¦å®éªŒ
- [ ] Replicaæ•°æ®é›†
- [ ] MP3Dæ•°æ®é›†
- [ ] DOZEåŠ¨æ€åœºæ™¯

# Week 11-13: è¡¥å……å®éªŒ
- [ ] æ¶ˆèå®éªŒ
- [ ] æ³›åŒ–æµ‹è¯•
- [ ] çœŸå®æœºå™¨äººï¼ˆå¦‚æœå¯èƒ½ï¼‰
```

---

## ğŸ“ è®ºæ–‡å†™ä½œè¦ç‚¹

### Titleé€‰é¡¹:
1. "Predictive Language-Grounded Navigation with Online Scene-Goal Graph Matching"
2. "Hierarchical Semantic Reasoning for Efficient Embodied Navigation"
3. "Unified Language-Grounded Mapping: From Pixels to Semantic Graphs"

### ä¸»è¦è´¡çŒ®ï¼ˆå†™åˆ°è®ºæ–‡é‡Œï¼‰:
1. **Language-Grounded Dual-Level Maps**: é¦–æ¬¡å°†vision-language value mapä¸åœ¨çº¿åŒå±‚æ˜ å°„ç»“åˆ
2. **Online Scene-Goal Graph**: é¦–ä¸ªæ”¯æŒåŠ¨æ€æ›´æ–°çš„åœºæ™¯-ç›®æ ‡å›¾åŒ¹é…ç³»ç»Ÿ
3. **Predictive Exploration**: åŸºäºLLMå’Œå¸¸è¯†æ¨ç†çš„é¢„æµ‹æ€§æ¢ç´¢ç­–ç•¥
4. **Comprehensive Evaluation**: åœ¨3ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼ŒåŒ…æ‹¬åŠ¨æ€åœºæ™¯

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### ç«‹å³å¼€å§‹çš„æ­¥éª¤:

1. **é˜…è¯»VLFMæºç **:
```bash
git clone https://github.com/bdaiinstitute/vlfm
cd vlfm
# é‡ç‚¹çœ‹ï¼švalue mapè®¡ç®—ã€frontierè¯„åˆ†
```

2. **é˜…è¯»UniGoalæºç **:
```bash
git clone https://github.com/bagh2178/UniGoal
cd UniGoal
# é‡ç‚¹çœ‹ï¼šå›¾æ„å»ºã€LLMé›†æˆ
```

3. **å®ç°ç¬¬ä¸€ä¸ªåŸå‹**:
```bash
cd ~/DualMap
# åˆ›å»ºæ–°åˆ†æ”¯
git checkout -b feature/language-grounded-maps

# å®ç°Language Value Map
touch utils/language_value_map.py
# ï¼ˆå‚è€ƒä¸Šé¢çš„ä»£ç ï¼‰
```

---

## ğŸ’¡ é¢å¤–å»ºè®®

1. **ä¸ä½œè€…äº¤æµ**:
   - è”ç³»VLFMä½œè€…ï¼ˆNaoki Yokoyamaï¼‰
   - è”ç³»UniGoalä½œè€…ï¼ˆHang Yinï¼‰
   - å¯èƒ½ä¼šæœ‰åˆä½œæœºä¼š

2. **å…³æ³¨æœ€æ–°è¿›å±•**:
   - CVPR 2025 ç›¸å…³è®ºæ–‡
   - ICRA 2025 workshop
   - Embodied AIç›¸å…³ä¼šè®®

3. **ä»£ç å¼€æºç­–ç•¥**:
   - åŠæ—©å¼€æºï¼ˆæå‡å½±å“åŠ›ï¼‰
   - æä¾›demoè§†é¢‘
   - è¯¦ç»†çš„æ–‡æ¡£å’Œæ•™ç¨‹

4. **çœŸå®æœºå™¨äººéªŒè¯**:
   - å¦‚æœæœ‰æœºå™¨äººå¹³å°ï¼ˆTurtleBot, Spotç­‰ï¼‰
   - çœŸå®å®éªŒä¼šå¤§å¤§å¢å¼ºè®ºæ–‡è¯´æœåŠ›
   - IROS/ICRAç‰¹åˆ«é‡è§†

---

**æ€»ç»“**: æˆ‘æœ€æ¨è**æ–¹æ¡ˆA**ï¼ˆLanguage-Grounded + Scene-Goal Graph + Predictiveï¼‰ï¼Œè¿™ä¸ªç»„åˆåˆ›æ–°æ€§å¼ºã€ç³»ç»Ÿæ€§å¥½ã€å®éªŒæ½œåŠ›å¤§ï¼Œé€‚åˆå†²å‡»CVPR/ICCV/NeurIPSè¿™æ ·çš„é¡¶ä¼šã€‚å¦‚æœæ—¶é—´ç´§è¿«ï¼Œå¯ä»¥å…ˆåš**æ–¹æ¡ˆC**å¿«é€Ÿå‘ä¸€ç¯‡ï¼Œç„¶åæ‰©å±•ä¸ºæ–¹æ¡ˆAã€‚
